{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and vectorizing words, training NMF topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    " \n",
    "data = pd.read_csv('topics.csv')\n",
    "import string\n",
    "import unidecode\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "def customtokenizer(article):\n",
    "    punc = str.maketrans('','',string.punctuation+\"''``''``\\\"\")\n",
    "    article_c = article.translate(punc)\n",
    "    dig = str.maketrans('','',string.digits)\n",
    "    article_c=article_c.translate(dig)\n",
    "    article_c = unidecode.unidecode(article_c)\n",
    "    article_c = article_c.lower()\n",
    "    regex = re.compile(r'(?u)\\b\\w\\w+\\b')\n",
    "    article_c = re.findall(regex,article_c)\n",
    "    stop_words = stopwords.words('english')\n",
    "    article_c = [y for y in article_c if y not in stop_words]\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    article_c = [stemmer.stem(y) for y in article_c] \n",
    "    return article_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madisonobrienjones/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['arent', 'couldnt', 'didnt', 'doesnt', 'dont', 'hadnt', 'hasnt', 'havent', 'isnt', 'mightnt', 'mustnt', 'neednt', 'shant', 'shes', 'shouldnt', 'shouldv', 'thatll', 'wasnt', 'werent', 'wont', 'wouldnt', 'youd', 'youll', 'youv'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=customtokenizer,max_features=2000, min_df=50,max_df=.75, stop_words=stopwords.words('english'))\n",
    " \n",
    "X = vectorizer.fit_transform(data['contents'])\n",
    " \n",
    "idx_to_word = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: plea,pay,special,admit,also,fbi,judg,conspiraci,prosecut,count,agent,charg,plead,year,offic,prison,trial,guilti,crimin,sentenc\n",
      "Topic 2: fraudul,client,websit,expens,deduct,complaint,credit,revenu,claim,refund,file,custom,busi,fals,injunct,incom,ir,return,prepar,tax\n",
      "Topic 3: miami,clinic,florida,medicaid,therapi,servic,kickback,fraudul,hhs,home,strike,beneficiari,bill,patient,hhsoig,medic,fraud,care,health,medicar\n",
      "Topic 4: said,equal,prohibit,tenant,harass,apart,alleg,race,complaint,act,settlement,disabl,famili,lawsuit,hud,civil,right,fair,discrimin,hous\n",
      "Topic 5: launch,via,video,epidem,apprehend,rescu,internet,obscen,abus,minor,imag,ceo,safe,project,children,childhood,sexual,exploit,pornographi,child\n",
      "Topic 6: complianc,million,natur,consent,site,reduc,compani,decre,requir,environ,facil,plant,water,clean,environment,emiss,settlement,pollut,air,epa\n",
      "Topic 7: kill,join,syria,new,york,provid,attempt,isi,state,fbi,organ,secur,nation,travel,materi,terror,attack,support,isil,terrorist\n",
      "Topic 8: maximum,propos,particip,execut,compani,twice,agre,ongo,anticompetit,charg,conspiraci,industri,automot,rig,fine,competit,bid,fix,price,antitrust\n",
      "Topic 9: hear,employe,practic,origin,nation,elig,impair,verif,provis,hire,hotlin,status,antidiscrimin,discrimin,worker,citizenship,immigr,ina,osc,employ\n",
      "Topic 10: perez,beat,obstruct,prison,hate,abus,constitut,former,sheriff,jail,fbi,incid,counti,violat,correct,offic,assault,inmat,civil,right\n",
      "Topic 11: juri,unseal,beyond,fals,doubt,supersed,face,accus,unless,maximum,grand,mere,proven,innoc,presum,defend,count,charg,alleg,indict\n",
      "Topic 12: initi,complianc,line,modif,american,ensur,facil,requir,tollfre,accommod,citi,equal,individu,peopl,counti,civic,agreement,access,disabl,ada\n",
      "Topic 13: former,navi,militari,iraq,afghanistan,award,payment,crimin,corrupt,procur,fcpa,compani,offici,defens,govern,contractor,briberi,armi,bribe,contract\n",
      "Topic 14: servic,unit,medicaid,lawsuit,recoveri,whistleblow,physician,state,act,resolv,patient,program,hospit,govern,alleg,fals,care,settlement,claim,health\n",
      "Topic 15: cocain,crimin,robberi,rival,sheriff,violenc,street,enterpris,drug,firearm,polic,ms,counti,aka,abt,texa,racket,murder,member,gang\n",
      "Topic 16: mail,file,count,use,coconspir,sentenc,obtain,debit,prison,middl,fraud,card,fraudul,check,aggrav,alabama,stolen,theft,refund,ident\n",
      "Topic 17: consum,million,trade,victim,wire,market,credit,crime,borrow,lend,forc,scheme,invest,task,mortgag,investor,bank,loan,fraud,financi\n",
      "Topic 18: discriminatori,ensur,section,oversea,offici,personnel,requir,activ,languag,feder,counti,act,ballot,jurisdict,monitor,observ,poll,voter,elect,vote\n",
      "Topic 19: protect,pharmaceut,inspect,misbrand,adulter,injunct,dea,civil,defend,supplement,compani,prescript,complaint,distribut,consum,manufactur,product,food,fda,drug\n",
      "Topic 20: local,work,agenc,holder,cop,public,safeti,nation,indian,award,offic,grant,crime,enforc,polic,program,law,violenc,tribal,communiti\n",
      "Topic 21: forc,select,northern,task,mortgag,counti,financi,homeown,fraud,california,public,francisco,properti,san,rig,bid,real,foreclosur,estat,auction\n",
      "Topic 22: minor,vulner,smuggl,civil,prosecut,immigr,young,said,mexico,labor,state,unit,right,women,crime,human,prostitut,sex,traffick,victim\n",
      "Topic 23: file,oblig,armi,job,serv,duti,civilian,veteran,complaint,member,posit,uniform,labor,servicememb,servic,right,militari,reemploy,employ,userra\n",
      "Topic 24: environ,marin,illeg,speci,engin,book,ocean,oili,record,environment,wast,wildlif,fish,water,discharg,vessel,ship,guard,oil,coast\n",
      "Topic 25: entiti,fund,transfer,open,program,agreement,disclosur,accounthold,foreign,switzerland,taxpay,client,ir,asset,ub,undeclar,offshor,swiss,account,bank\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=25, solver=\"mu\")\n",
    " \n",
    "W = nmf.fit_transform(X)\n",
    " \n",
    "H = nmf.components_\n",
    " \n",
    "# print the topics\n",
    " \n",
    "for i, topic in enumerate(H):\n",
    " \n",
    "    print(\"Topic {}: {}\".format(i + 1, \",\".join([str(x) for x in idx_to_word[topic.argsort()[-20:]]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming test text and investigating properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['environment ships illegal trafficking sea']\n",
    "test = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = nmf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.44948350e-015, 0.00000000e+000, 0.00000000e+000,\n",
       "        7.75194048e-039, 4.04475122e-092, 1.53458460e-004,\n",
       "        1.84029265e-044, 0.00000000e+000, 9.29379432e-030,\n",
       "        5.25763840e-037, 6.54008190e-019, 7.91130011e-018,\n",
       "        0.00000000e+000, 0.00000000e+000, 6.31076301e-005,\n",
       "        1.03212432e-138, 1.00559678e-022, 4.53067523e-029,\n",
       "        1.39163509e-003, 4.00158395e-017, 3.22841249e-011,\n",
       "        5.34503655e-002, 4.27736713e-100, 7.30765673e-002,\n",
       "        3.45834323e-038]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13081, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13081x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1820303 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing articles most similar to test text by cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California Man Sentenced to One Year in Prison for Illegal Sale of Black Rhinoceros Horns\n",
      "Maine Fisherman Sentenced for Illegally Trafficking American Eels\n",
      "New York Antiques Dealer Sentenced to 37 Months in Prison for Wildlife Smuggling\n",
      "Statements of Associate Attorney General Tony West and Acting Assistant Attorney General of Enrd on the National Strategy for Combatting Wildlife Trafficking\n",
      "Tennessee Men Plead Guilty to Illegally Trafficking Narwhal Tusks\n",
      "Massachusetts Antique Dealer Sentenced to 33 Months in Prison for Trafficking in \n",
      "Illegally-Imported Narwhal Tusks and Sperm Whale Teeth\n",
      "Irish National Sentenced to Serve 14 Months in Prison  for Trafficking of Endangered Rhinoceros Horns\n",
      "Long Island Man Pleads Guilty to Trafficking in Rhinoceros Horns \n",
      "Antiques Dealer Sentenced in Manhattan to Two Years in Prison for Smuggling Cups Made from Rhinoceros Horns\n",
      "Canadian Antiques Dealer Sentenced to 30 Months in Prison for Smuggling Rhinoceros Horns, Elephant Ivory and Coral\n",
      "Foreign National Pleads Guilty to Smuggling Rhinoceros Horn \n",
      "Canadian Antique Dealer Charged with Trafficking Wildlife\n",
      "California Man Convicted for Role in the Illegal Sale of Black Rhinoceros Horns \n",
      "Miami Taxidermist Sentenced for Wildlife Smuggling\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "for each in list(cosine_similarity(nm,W).argsort()[0][-15:-1]):\n",
    "    print(data.at[each,'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
